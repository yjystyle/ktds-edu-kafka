# Kafka Hands-in

>Kafka On Kubernetes





# 1. Strimzi



## 1) Strimzi 란 ?



Strimzi는 Kubernetes 클러스터에서 Apache Kafka를 실행하는 프로세스를 단순화시키는 오픈소스 툴이다.

- Strimzi는 Kubernetes에서 Kafka를 실행하기 위한 컨테이너 이미지 및 Operator를 제공함

- Operator 는 Kubernetes 에서 운영작업을 단순화 하기 위해 제공되는 CRD(Custom Resource Definition) 의 운영체
- Strimzi Operator 는 Kubernetes 기능을 확장하여 Kafka 배포와 관련된 일반적이고 복잡한 작업을 자동화



## 2) Strimzi Operator

Strimzi는 Kubernetes 클러스터 내에서 실행되는 Kafka 클러스터를 관리하기 위한 Operator를 제공한다.

- Cluster Operator

  - Apache Kafka Cluster

  - Kafka Connect

  - Kafka MirrorMaker

  - Kafka Bridge

  - Kafka Exporter

  - Cruise Control 및 Entity Operator 배포 및 관리

- Topic  Operator

  Kafka Topic 관리

- User Operator

  Kafka User 관리



![Operators within the Strimzi architecture](2.kafka-hands-in.assets/operators.png)





# 2. Strimzi Install

준비된 Bastion Server 에 Strimzi (kafka) 를 설치한다.



## 1) namespace 생성

strimzi operator 와 kafka cluster를 설치하기위해 kafka namespace 를 생성한다.



```sh
# namespace 생성
$ kubectl create ns kafka

# 확인
$ kubectl get ns
NAME              STATUS   AGE
kube-system       Active   8m25s
default           Active   8m25s
kube-public       Active   8m25s
kube-node-lease   Active   8m24s
kafka             Active   5s


```





## 2) [참고] Strmzi download

사전에 download 받아 놓은 실습자료에 설치 파일이 존재한다.

참고로 strimzi site 에서 최신버젼을 다운로드 받을 수 있다.

- 링크: https://strimzi.io/downloads/

```sh

$ mkdir -p ~/temp/strimzi
  cd ~/temp/strimzi

# download
$ wget https://github.com/strimzi/strimzi-kafka-operator/releases/download/0.39.0/strimzi-0.39.0.zip


$ ll
-rw-rw-r-- 1 ubuntu ubuntu 5649439 Dec 20 19:54 strimzi-0.39.0.zip


$ unzip strimzi-0.39.0.zip
#unzip 이 없으면 설치
# apt install unzip


$ cd  ~/temp/strimzi/strimzi-0.39.0/


$ ll
-rw-r--r--  1 ubuntu ubuntu 62045 Dec 20 17:14 CHANGELOG.md
drwxr-xr-x  4 ubuntu ubuntu  4096 Dec 20 17:15 docs/
drwxr-xr-x 11 ubuntu ubuntu  4096 Dec 20 17:14 examples/
drwxr-xr-x  8 ubuntu ubuntu  4096 Dec 20 17:14 install/

```

* 제약사항
  * Kubernetes 1.21 이상에 Strimzi 0.39.0 배포가능



## 3) [참고] Single namespace 설정

- single namespace 감시 모드로 설치진행
  - strimzi operator 는 다양한 namespace 에서 kafka cluster 를 쉽게 생성할 수 있는 구조로 운영이 가능하다.  
  - 이때 STRIMZI_NAMESPACE 를 설정하여 특정 namespace 만으로 cluster 를 제한 할 수 있다.  

```sh

$ cd  ~/temp/strimzi/strimzi-0.39.0


# 변경
$ sed -i 's/namespace: .*/namespace: kafka/' ./install/cluster-operator/*RoleBinding*.yaml


# 확인
$ cat install/cluster-operator/*RoleBinding*.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: kafka                        # <-- 이렇게 보인다면 성공
...


```





## 4) Operator Deploy

- kafka namespace 를 watch 할 수 있는 권한 부여

```sh
$ cd  ~/temp/strimzi/strimzi-0.39.0

# 1) Deploy the CRDs
$ kubectl -n kafka create -f ./install/cluster-operator/


# 2) CRD 확인
$ kubectl -n kafka get crd
NAME                                    CREATED AT
...
kafkabridges.kafka.strimzi.io              2024-02-24T06:48:09Z
kafkaconnectors.kafka.strimzi.io           2024-02-24T06:48:09Z
kafkaconnects.kafka.strimzi.io             2024-02-24T06:48:08Z
kafkamirrormaker2s.kafka.strimzi.io        2024-02-24T06:48:09Z
kafkamirrormakers.kafka.strimzi.io         2024-02-24T06:48:09Z
kafkanodepools.kafka.strimzi.io            2024-02-24T06:48:09Z
kafkarebalances.kafka.strimzi.io           2024-02-24T06:48:09Z
kafkas.kafka.strimzi.io                    2024-02-24T06:48:08Z
kafkatopics.kafka.strimzi.io               2024-02-24T06:48:08Z
kafkausers.kafka.strimzi.io                2024-02-24T06:48:08Z

#  *.*.strimzi.io 라는 CRD 가 생성되었다.


# 3) operator 설치 확인
$ kubectl -n kafka get deploy
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
strimzi-cluster-operator   0/1     1            0           60s


$ kubectl -n kafka get pod
NAME                                        READY   STATUS    RESTARTS   AGE
strimzi-cluster-operator-7bb5468c59-qlb44   1/1     Running   0          74s






# 4) pod log 확인
$ kubectl -n kafka logs deploy/strimzi-cluster-operator
...
2024-02-25 12:14:53 INFO  ClusterOperator:139 - Setting up periodic reconciliation for namespace kafka
2024-02-25 12:14:53 INFO  Main:206 - Cluster Operator verticle started in namespace kafka without label selector
2024-02-25 12:14:54 INFO  StrimziPodSetController:560 - Informers are in-sync

# Cluster Operator verticle started  메세지가 나오면 정상설치 완료 


```



# 3. Kafka Cluster 생성

## 1) Kafka Cluster 생성



### (1) Kafka cluster 생성

> scram -512  인증 방식의 Cluster생성

#### git clone

```sh
$ mkdir -p ~/githubrepo
  cd ~/githubrepo

$ git clone https://github.com/ssongman/ktds-edu-kafka.git

# 존재한다면 최신데이터로 다시 pull

$ cd ~/githubrepo/ktds-edu-kafka
$ git pull

```



#### kafka cluster 생성

```sh
$ cd ~/githubrepo/ktds-edu-kafka

$ cat ./kafka/strimzi/kafka/12.kafka-ephemeral-auth.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster
  namespace: kafka
spec:
  kafka:
    version: 3.6.1
    replicas: 3
    authorization:
      type: simple
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
        authentication:
          type: scram-sha-512
      - name: tls
        port: 9093
        type: internal
        tls: true
    config:
      offsets.topic.replication.factor: 2
      transaction.state.log.replication.factor: 2
      transaction.state.log.min.isr: 2
      default.replication.factor: 2
      min.insync.replicas: 1
      inter.broker.protocol.version: "3.6"
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}

# kafka Cluster 생성
$ kubectl -n kafka apply -f ./kafka/strimzi/kafka/12.kafka-ephemeral-auth.yaml

```

- 인증메커니즘

  - SASL 은 인증 및 보안 서비스를 제공하는 프레임워크이다.
  - 위 yaml 파일의 인증방식은 scram-sha-512  방식인데 이는 SASL 이 지원하는 메커니즘 중 하나이며 Broker 를 SASL 구성로 구성한다.



### (2) Kafka Cluster 확인

```sh

# cluster 생성중인 상태 확인
$ kubectl -n kafka get pod -w
...
Ctrl+C

$ kubectl -n kafka get pod
NAME                                         READY   STATUS    RESTARTS   AGE
my-cluster-entity-operator-7cfdb67c4-d4qc7   3/3     Running   0          3m24s
my-cluster-kafka-0                           1/1     Running   0          4m3s
my-cluster-kafka-1                           1/1     Running   0          4m3s
my-cluster-kafka-2                           1/1     Running   0          4m3s
my-cluster-zookeeper-0                       1/1     Running   0          4m28s
my-cluster-zookeeper-1                       1/1     Running   0          4m28s
my-cluster-zookeeper-2                       1/1     Running   0          4m28s
strimzi-cluster-operator-86864b86d5-8rlfx    1/1     Running   0          5h24m

# kafka broker 3개와  zookeeper 3개 실행된것을 확인 할 수 있다.
# kafka cluster 가 구성되는데 약 2분정도 소요됨



# Kafka Cluster 확인
$ kubectl -n kafka get kafka
NAME         DESIRED KAFKA REPLICAS   DESIRED ZK REPLICAS   READY   WARNINGS
my-cluster   3                        3                     True

# kafka Cluster 의 ready 상태가 True 인것을 확인하자.

```







### (3) [참고] Kafka cluster 생성(No 인증)

아래는 인증없이 접근 가능한 kafka cluster 를 생성하는 yaml 이므로 참고만 하자.

```sh
$ cd ~/githubrepo/ktds-edu-kafka

$ cat ./kafka/strimzi/kafka/11.kafka-ephemeral-no-auth.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster
  namespace: kafka
spec:
  kafka:
    version: 3.5.1
    replicas: 3
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      default.replication.factor: 3
      min.insync.replicas: 2
      inter.broker.protocol.version: "3.5"
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {} 


```







## 2)  KafkaUser

- kafka cluster 생성시 scram-sha-512 type 의 authentication 를 추가했다면 반드시 KafkaUser 가 존재해야 한다.

- KafkaUser 를 생성하면 secret 에 Opaque 가 생성되며 향후 인증 password 로 사용된다.
- 어떤 topic 에 어떻게 접근할지 에 대한 ACL 기능을 추가할 수 있다.



### (1) User 정책

아래와 같이 ACL (Access Control List) 정책을 지정할 수 있다.

- sample user 별 설명

```
ㅇ my-user
my 로 시작하는 모든 topic을 처리할 수 있음
my 로 시작하는 모든 group을 Consume 가능

ㅇ edu-user
edu 로 시작하는 모든 topic을 처리할 수 있음
edu 로 시작하는 모든 group을 Consume 가능

ㅇ order-user
order로 시작하는 모든 topic을 처리할 수 있음
order로 시작하는 모든 group을 Consume 가능

ㅇ order-user-readonly
order로 시작하는 모든 topic을 읽을 수 있음
order로 시작하는 모든 group을 Consume 가능
```



### (2) my-edu-admin 생성

#### KafkaUser 생성

```sh
$ cd ~/githubrepo/ktds-edu-kafka

$ cat ./kafka/strimzi/user/11.my-edu-admin.yaml
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaUser
metadata:
  name: my-edu-admin
  labels:
    strimzi.io/cluster: my-cluster
  namespace: kafka
spec:
  authentication:
    type: scram-sha-512
  authorization:
    type: simple
    acls:
      - operation: All
        resource:
          type: topic
          name: my
          patternType: prefix
      - operation: All
        resource:
          name: my
          patternType: prefix
          type: group
      - operation: All
        resource:
          type: topic
          name: edu
          patternType: prefix
      - operation: All
        resource:
          name: edu
          patternType: prefix
          type: group

---


# KafkaUser 생성 명령 실행
$ kubectl -n kafka apply -f ./kafka/strimzi/user/11.my-edu-admin.yaml

# kafkauser 확인
$ kubectl -n kafka get kafkauser
NAME           CLUSTER      AUTHENTICATION   AUTHORIZATION   READY
my-edu-admin   my-cluster   scram-sha-512    simple          True


# Ready 상태가 True인것을 확인하자.
```

- ACL 권한설명

  - my  또는 edu 로 시작하는 topic을 모두 처리가능
  - ex) my-board-create,  my-board-update,  edu-topic
- ACLs Operation 
    * 관련링크 : https://docs.confluent.io/platform/current/kafka/authorization.html



#### [참고] kafkauser Sample

```yaml

apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: tls
  authorization:
    type: simple
    acls:
      # Example consumer Acls for topic my-topic using consumer group my-group
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operations:
          - Describe
          - Read
        host: "*"
      - resource:
          type: group
          name: my-group
          patternType: literal
        operations:
          - Read
        host: "*"
      # Example Producer Acls for topic my-topic
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operations:
          - Create
          - Describe
          - Write
        host: "*"

```






#### password 확인  - ★★★

```sh

# secret 확인
$ kubectl -n kafka get secret my-edu-admin
NAME           TYPE     DATA   AGE
my-edu-admin   Opaque   2      46s


# secret 내에서 password 추출
$ kubectl -n kafka get secret my-edu-admin -o jsonpath='{.data.password}' | base64 -d
qKtohJldaIsr8oVkWSXhaHSDSdvnZxir
qKtohJldaIsr8oVkWSXhaHSDSdvnZxir

# prompt 와 붙어 있으니 잘 확인할것

# user/pass         <-- Password 를 반드시 기억하세요.
## my-edu-admin / qKtohJldaIsr8oVkWSXhaHSDSdvnZxir

```



※ Typora 를 사용하고 있다면 본문서에 등장하는 password 를 모두 자신의 password 로 Replace 하여 사용하자.

```
CTRL + H

qKtohJldaIsr8oVkWSXhaHSDSdvnZxir --> (자신의 Password) 로 변경

```







## 3) KafkaTopic



### (1) Topic 정책 

앞서 KafkaUser 의 ACL 기능을 이용해서 kafka topic 을 제어하는 방법을 확인했다.  

my~  또는 edu 로 시작하는 topic 을 모두 처리가능하므로 my-topic 이라는 이름으로 topic 을 생성해 보자.



### (2) KafkaTopic 생성

```sh
$ cd ~/githubrepo/ktds-edu-kafka


$ cat ./kafka/strimzi/topic/11.kafka-topic.yaml
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: my-topic
  labels:
    strimzi.io/cluster: my-cluster
  namespace: kafka
spec:
  partitions: 3
  replicas: 2
  config:
    #retention.ms: 7200000      # 2 hour
    retention.ms: 86400000      # 24 hours
    segment.bytes: 1073741824   # 1GB
---

# topic 생성 명령 실행
$ kubectl -n kafka apply -f ./kafka/strimzi/topic/11.kafka-topic.yaml


# topic 생성 확인
$ kubectl -n kafka get kafkatopic my-topic
NAME       CLUSTER      PARTITIONS   REPLICATION FACTOR   READY
my-topic   my-cluster   3            3                    True


```



### (3) Topic  상세 확인

```sh

$ kubectl -n kafka get kafkatopic my-topic -o yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"kafka.strimzi.io/v1beta2","kind":"KafkaTopic","metadata":{"annotations":{},"labels":{"strimzi.io/cluster":"my-cluster"},"name":"my-topic","namespace":"kafka"},"spec":{"config":{"retention.ms":86400000,"segment.bytes":1073741824},"partitions":3,"replicas":3}}
  creationTimestamp: "2023-09-02T14:01:01Z"
  generation: 1
  labels:
    strimzi.io/cluster: my-cluster
  name: my-topic
  namespace: kafka
  resourceVersion: "2086"
  uid: d83f3976-1866-4883-bbd8-1af681270282
spec:
  config:
    retention.ms: 86400000
    segment.bytes: 1073741824
  partitions: 3
  replicas: 3
status:
  conditions:
  - lastTransitionTime: "2023-09-02T14:01:01.777646039Z"
    status: "True"
    type: Ready
  observedGeneration: 1
  topicName: my-topic



```

- status 에서 true, ready 임을 확인하자.





### [참고] ICIS-TR Topic Name 정책

topiic 명칭을 어떻게 정하는지에 대해서 다양한 시나리오를 생각해 볼 수 있다. 아래 특정 프로젝트의 topic name 정책을 살펴보자.

- topic 정책 및 샘플

```
# 정책
[Part명]-[서비스명]-[서브도메인]-[사용자정의]


# 샘플
order-intl-board-create
order-intl-board-update
order-intl-board-delete

bill-intl-board-create
bill-intl-board-update
bill-intl-board-delete

rater-intl-board-create
rater-intl-board-update
rater-intl-board-delete
```









# 4. Accessing Kafka

- Kafka 의 주요기능 중 하나는 확장성이다.  즉, 데이터를 분할하고 여러 브로커에 파티션을 분산하여 관리한다. 
- 그러므로 이러한 분산환경은 Client 가 Broker 에 연결하는 방식에도 큰 영향을 미친다. 
- Strimzi kafka 는 Kubernetes 플랫폼 내에서 실행중이므로 Kubernetes 플랫폼 내부/외부에서 접근할때 각각 방식이 다르다. 



## 1) Broker 접근 방식의 이해



### (1) Client 와 Broker Connect

- 특정 파티션에 지정된 클라이언트는 해당 파티션을 호스팅하는 리더 브로커에 직접 연결한다.

- 그러므로 브로커간 데이터전달 불필요하며 이러한 방식은 클러스터내 트래픽의 양을 줄이는데 도움이 됨

![파티션에 연결하는 클라이언트](2.kafka-hands-in.assets/2019-04-17-connecting-to-leader.png)



클라이언트는 어떻게 해당 브로커의 위치를 알 수 있을까?



### (2) kafka discovery protocol

- Kafka에는 자체 discovery protocol 이 있음

- Kafka 클라이언트가 Kafka 클러스터에 연결할 때 먼저 클러스터의 구성원인 브로커에 연결하고 하나 이상의 Topic에 대한 메타데이터 를 요청함
- 메타데이터에는 Topic, 해당 Partition 및 이러한 Partition 을 호스팅하는 브로커에 대한 정보가 포함됨 
- 모든 브로커는 Zookeeper를 통해 모두 동기화되기 때문에 전체 클러스터에 대해 이 데이터를 가지고 있음
- 따라서 클라이언트가 처음으로 연결된 브로커는 중요하지 않으며 모든 브로커가 동일한 응답을 제공함

![Kafka 클라이언트와 Kafka 클러스터 간의 연결 흐름](2.kafka-hands-in.assets/2019-04-17-connection-flow.png)

- 클라이언트는 *메타데이터* 를 사용 하여 주어진 파티션에 쓰거나 읽으려고 할 때 연결할 위치를 파악함

- *메타데이터* 에 사용된 브로커 주소 는 브로커가 실행되는 시스템의 호스트 이름을 기반으로 브로커 자체에서 생성됨
- 또는 `advertised.listeners` 옵션을 사용하여 사용자가 구성할 수 있음





### (3) Internal Access 과 External Access

DEV환경과 PRD 환경을 각각 생각해 보자.

PRD 환경의 경우 Kubernetes Cluster내에 Kafka가 설치되어 있고 연결을 원하는 App이 해당 클러스터 내에 배포된 상태에서 Kafka를 접속한다.

그러므로 Kafka 를 접속시 Cluster 내부 주소체계를 사용한다.  (Internal Access)

하지만 DEV환경의 경우 개발자PC와 같이 Kubernetes Cluster 외부에서 접근해야 하므로 별도의 주소체계가 있어야 한다. (External Access)

이러한 부분의 차이가 있음을 이해하자.





### (4) 클러스터 내부에서 연결

- Kafka 클러스터와 동일한 Kubernetes 클러스터 내에서 실행되는 클라이언트는 Kubernetes `service` 를 이용해서 접근함
- Strimzi는 Kafka 브로커를 StatefulSet로 실행함
- 그러므로 `Kubernetes headless service` 를 사용하여 각 pod별 고유한  DNS 이름을 가질 수 있음
- Strimzi는 이러한 DNS 이름을 `advertised.listeners`로 사용하고 있음



![동일한 Kubernetes 클러스터 내에서 Kafka에 액세스](2.kafka-hands-in.assets/2019-04-17-inside-kubernetes.png)



- 초기 연결은 *메타데이터* 를 가져오기 위해 일반 Kubernetes service 를 사용하여 수행됨 
- 후속 연결은 다른 headless Kubernetes service 에서 Pod에 제공한 DNS 이름을 사용하여 열림 





### (5) 클러스터 외부에서 연결(Node Port)

- Kubernetes 클러스터 외부에서 Kafka Client 가 접근시에는 Node Port Type 의 Service 를 통해서 접근할 수 있음
- Client 는 특정 Node IP 의 Node Port 를 이용해서 각각의 POD 로 연결할 수 있음
- 참고 : https://strimzi.io/blog/2019/04/23/accessing-kafka-part-2/



![Accessing Kafka using per-pod services](assets/2019-04-23-per-pod-services.png)







## 2) Internal Access



### (1) Kafka Cluster Service 확인



```sh
$ kubectl -n kafka get svc
NAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                               AGE
my-cluster-kafka-bootstrap    ClusterIP   10.105.0.19     <none>        9091/TCP,9092/TCP,9093/TCP            75m
my-cluster-kafka-brokers      ClusterIP   None            <none>        9090/TCP,9091/TCP,9092/TCP,9093/TCP   75m
my-cluster-zookeeper-client   ClusterIP   10.105.55.137   <none>        2181/TCP                              75m
my-cluster-zookeeper-nodes    ClusterIP   None            <none>        2181/TCP,2888/TCP,3888/TCP            75m


$ kubectl -n kafka get pod
NAME                                         READY   STATUS    RESTARTS   AGE
strimzi-cluster-operator-fd6fb56f6-f8d98     1/1     Running   0          55m
my-cluster-zookeeper-1                       1/1     Running   0          27m
my-cluster-zookeeper-0                       1/1     Running   0          27m
my-cluster-zookeeper-2                       1/1     Running   0          27m
my-cluster-kafka-1                           1/1     Running   0          27m
my-cluster-kafka-2                           1/1     Running   0          27m
my-cluster-kafka-0                           1/1     Running   0          27m
my-cluster-entity-operator-d44f86494-2k9l8   3/3     Running   0          26m
```

- my-cluster-kafka-bootstrap 이 일반 kubernetes service 이며 POD 로 트래픽을 RR 방식으로 연결한다.
- my-cluster-kafka-brokers 는 ip 가 없는 headless service 이다. 그러므로 pod 명을 붙여서 DNS 로 사용된다.
  - headless service 사용예시
    - my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc
    - my-cluster-kafka-1.my-cluster-kafka-brokers.kafka.svc
    - my-cluster-kafka-2.my-cluster-kafka-brokers.kafka.svc

- 우리는 Cluster 내에서  my-cluster-kafka-bootstrap:9092 로 접근을 시도할 것이다.
  - 이후 kafka 로부터 전달 받은 metadata 는 headless service 들이 포함되어 있을 것이다.






### (2) kafkacat 로 확인

Kubernetes Cluster 내에서 kafka 접근 가능여부를 확인하기 위해 kafka Client 용 app 인 kafkacat 을 설치하자.



#### kafkacat 설치

```sh
# kafka cat 설치
$ kubectl -n kafka create deploy kafkacat \
    --image=confluentinc/cp-kafkacat:latest \
    -- sleep 365d

# 설치진행 확인
$ kubectl -n kafka get pod
NAME                                         READY   STATUS              RESTARTS   AGE
kafkacat-7648db7f48-wg4hn                    0/1     ContainerCreating   0          4s


## READY 상태가 1/1 로 변할때까지 대기...


# pod 내부로 진입( bash 명령 수행)
$ kubectl -n kafka exec -it deploy/kafkacat -- bash
[appuser@kafkacat-7648db7f48-wg4hn ~]$



```



#### ※ [참고] windows WSL에서 수행시...
windows 환경의 gitbash 를 이용해 pod 내부명령을 수행한다면 prompt 가 보이지 않을수도 있다.

이런경우 windows 에서 linux 체제와 호환이 되지 않아서 발생하는 이슈이다.

아래와 같이 winpty 를 붙인다면 prompt 가 보이니 참고하자.

```sh

# pod 내부명령 수행
$ winpty kubectl -n kafka exec -it deploy/kafkacat -- bash

```





#### pub/sub test

Terminal 을 두개 실행하여 pub 과 sub을 실행해 보자.



#### sub termnial 실행

```sh

# pod 내부로 진입( bash 명령 수행)
$ kubectl -n kafka exec -it deploy/kafkacat -- bash
[appuser@kafkacat-7648db7f48-wg4hn ~]$



# kafkacat pod 내부에서...
# $ kubectl -n kafka exec -it deploy/kafkacat -- bash

export BROKERS=my-cluster-kafka-bootstrap:9092
export KAFKAUSER=my-edu-admin
export PASSWORD=qKtohJldaIsr8oVkWSXhaHSDSdvnZxir        ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 
export TOPIC=my-topic
 
 
## topic 리스트
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD -L

Metadata for all topics (from broker -1: sasl_plaintext://my-cluster-kafka-bootstrap:9092/bootstrap):
 3 brokers:
  broker 0 at my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9092
  broker 2 at my-cluster-kafka-2.my-cluster-kafka-brokers.kafka.svc:9092 (controller)
  broker 1 at my-cluster-kafka-1.my-cluster-kafka-brokers.kafka.svc:9092
 1 topics:
  topic "my-topic" with 3 partitions:
    partition 0, leader 1, replicas: 1,2,0, isrs: 1,2,0
    partition 1, leader 0, replicas: 0,1,2, isrs: 0,1,2
    partition 2, leader 2, replicas: 2,0,1, isrs: 2,0,1

## 위 내용중 3개의 brokers 주소를 잘 이해하자.
## 위주소는 headless service 이용한 pod dns 이다.


## consumer
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -C -o -5


## 수신대기...


```



#### pub termnial 실행

terminal 을 한개 더 실행하여 아래와 같이 pub 테스트를 수행하자.

```sh

# pod 내부로 진입( bash 명령 수행)
$ kubectl -n kafka exec -it deploy/kafkacat -- bash
[appuser@kafkacat-7648db7f48-wg4hn ~]$



# kafkacat pod 내부에서...
# $ kubectl -n kafka exec -it deploy/kafkacat -- bash

 
## topic 리스트
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD -L
  
  



## terminal 을 한개 더 실행하여 위 환경변수 인식후 아래 producer 를 실행하자.
## producer
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -P -X acks=1 

# 임의의 text 입력


# 테스트 완료후
# Ctrl+C or Ctrl+D (exit) 수행하여 POD terminal 을 빠져나오자.
```





- Consumer 결과확인

```
% Reached end of topic my-topic [2] at offset 0
% Reached end of topic my-topic [0] at offset 0
% Reached end of topic my-topic [1] at offset 0

asdf
% Reached end of topic my-topic [2] at offset 1
asdf
% Reached end of topic my-topic [2] at offset 2
asdf
asd
% Reached end of topic my-topic [1] at offset 2
fsad
% Reached end of topic my-topic [2] at offset 3
f
% Reached end of topic my-topic [2] at offset 4
sdf
% Reached end of topic my-topic [1] at offset 3
asdfasd
% Reached end of topic my-topic [0] at offset 1
fas
% Reached end of topic my-topic [0] at offset 2
fsda
% Reached end of topic my-topic [0] at offset 3
fsa
% Reached end of topic my-topic [1] at offset 4

```

- offset 값이 partition 단위로 증가됨을 할 수 있다.





#### [참고] kafkacat 추가명령

```sh

## consumer group
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -C \
  -X group.id=my-board-group




## consumer group
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -C \
  -X group.id=order-intl-board-group -o -5



## producer : 입력모드
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -P -X acks=1
 


## 대량 발송 모드
$ cat > msg.txt
---
{"eventName":"a","num":1,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }
---

## producer : file mode
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -P ./msg.txt


## producer : while
while true; do kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -P ./msg.txt; done;

```





### (3) python 으로 확인

Kubernetes Cluster 내에서 kafka 접근 가능여부를 확인하기 위해 python 을 설치후 kafka 에 connect 해 보자.



#### python  설치

```sh
# bastion Serve 에서 수행

# python deploy
$ kubectl -n kafka create deploy python --image=python:3.9 -- sleep 365d


# 설치진행 확인
$ kubectl -n kafka get pod
...
python-fb57f7bd4-4w6pz                       1/1     Running   0              32s
...

## READY 상태가 1/1 로 변할때까지 대기...
## 약 1분 소요


# python pod 내부로 진입( bash 명령 수행)
$ kubectl -n kafka exec -it deploy/python -- bash
root@python-7d59455985-ml8vw:/#                  <-- 이런 prompt 가 정상


```





#### python library install

kafka 에 접근하기 위해서 kafka-python 을 설치해야 한다.

```bash
# python pod 내부에서
$ pip install kafka-python

Collecting kafka-python
  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 246.5/246.5 kB 7.8 MB/s eta 0:00:00
Installing collected packages: kafka-python
Successfully installed kafka-python-2.0.2

```



#### [참고] kafka host 확인

```sh
# internal 접근을 위한 host 확인
# nc 명령으로 접근가능여부를 확인할 수 있다.

$ apt update
$ apt install netcat

$
nc -zv my-cluster-kafka-bootstrap.kafka.svc 9092
nc -zv my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc 9092
nc -zv my-cluster-kafka-1.my-cluster-kafka-brokers.kafka.svc 9092
nc -zv my-cluster-kafka-2.my-cluster-kafka-brokers.kafka.svc 9092

```



#### consumer

consumer 실행을 위해서 python cli 환경으로 들어가자.

```sh
# python pod 내부에서
$ python
Python 3.9.18 (main, Aug 26 2023, 01:24:18)
[GCC 12.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>

```



CLI 환경에서 아래  Python 명령을 하나씩 실행해 보자.

```python

from kafka import KafkaConsumer

# 개인환경으로 변경
bootstrap_servers='my-cluster-kafka-bootstrap.kafka.svc:9092'
sasl_plain_password='qKtohJldaIsr8oVkWSXhaHSDSdvnZxir'             ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 
sasl_plain_username='my-edu-admin'
group_id='my-topic-group'

consumer = KafkaConsumer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username=sasl_plain_username,
                        sasl_plain_password=sasl_plain_password,
                        auto_offset_reset='earliest',
                        enable_auto_commit= True,
                        group_id=group_id)



# my-user로 확인가능한 topic 목록들을 확인할 수 있다.
consumer.topics()

# 사용할 topic 지정(구독)
consumer.subscribe("my-topic")

# 구독 확인
consumer.subscription()
#{'my-topic'}            <-- 해당 Topic 이 출력되어야 한다.



# 메세지 읽기
for message in consumer:
   print("topic=%s partition=%d offset=%d: key=%s value=%s" %
        (message.topic,
          message.partition,
          message.offset,
          message.key,
          message.value))

# 수신대기중....


'''
topic=my-topic partition=0 offset=38: key=None value=b'{"eventName":"a","num":88,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=39: key=None value=b'{"eventName":"a","num":90,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=40: key=None value=b'{"eventName":"a","num":96,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
'''
```







#### producer

producer 실행을 위해서 별도의 terminal 을 실행한 후 python cli 환경으로 들어가자.

```sh

# python pod 내 진입(bash 실행)
$ kubectl -n kafka exec -it deploy/python -- bash
root@python-7d59455985-ml8vw:/#                  <-- 이런 prompt 가 정상



$ python

Python 3.9.18 (main, Aug 26 2023, 01:24:18)
[GCC 12.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.

>>>

```



internal 에서 접근시에는 인증서가 없는  9092 port 접근이므로 사용되는 protocol은 SASL_PLAINTEXT 이다.CLI 환경에서 아래  Python 명령을 하나씩 실행해 보자.

```python

from kafka import KafkaProducer
from time import sleep

# 개인환경으로 변경
bootstrap_servers='my-cluster-kafka-bootstrap.kafka.svc:9092'
sasl_plain_password='qKtohJldaIsr8oVkWSXhaHSDSdvnZxir'             ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 
sasl_plain_username='my-edu-admin'
group_id='my-topic-group'

producer = KafkaProducer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username=sasl_plain_username,
                        sasl_plain_password=sasl_plain_password)

# 아래 명령 부터 Consumer 수신을 관찰하면서 수행하자.
producer.send('my-topic', b'python test1')
producer.send('my-topic', b'python test2')
producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % 1)

# 10000건을 0.5초에 한번씩 발송해보자.
for i in range(10000):
    print(i)
    sleep(0.5)
    producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)

    
# 테스트를 끝내려면 Ctrl + C 로 중지하자.
```



- 대량 발송(성능테스트)

```python
# 만건 테스트
import time
start_time = time.time() # 시작시간
for i in range(10000):
    # print(i)
    producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)

end_time = time.time() # 종료시간
print("duration time :", end_time - start_time)  # 현재시각 - 시작시간 = 실행 시간




# 1만건 테스트 결과
# duration time : 29.434531688690186
# duration time : 25.90397334098816

```



- 참고

```python
# 2만건 테스트
for i in range(10001, 20000):
    print(i)
    producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)
    
```



- python 종료 Ctrl+D 

```sh
# POD Terminal 을 빠져나가려면 exit(Ctrl+D)
```







### (4) kafkacat / python 으로 확인

sub 은 python 으로 유지하면서 pub 은 kafkacat 으로 데이터를 전송하는 테스트를 진행해 보자.









## 3) External Access(Node Port)



### (1) Strimzi가 제공하는 외부 접근방식

- Strimzi 는 외부에서 접근가능하도록  다양한 기능을 제공함

- Strimzi 가 제공하는 외부 접근방식
  - Node port
  - Ingress
  - Openshift Route
  - Load Balancer



### (2) Node Port



#### Node IP 확인

- node port 를 인식할 수 있는 본인 Bastion Server IP를 확인해야 한다.
- Bastion Server IP 는 개인별로 부여된 IP 이므로 이를 사용하자.

  ※ Typora 를 사용하고 있다면 본문서에 등장하는 34.130.165.53 를 모두 자신의 IP 로 Replace 사용하자.

```
CTRL + H

34.130.165.53 --> (자신의 Bastion Server IP)로 변경

3.38.104.137

```



- 이 IP 는 아래 Node Port 등록시 nip host 에 사용된다.

```sh
# nip 
my-cluster.kafka.3.38.104.137.nip.io
```

  





#### NodePort Listener 등록

- Kafka Cluster 를 수정모드로 변경하여 node port  listener 를 삽입하자.
- node Port 를 직접 명시할 수 있다.
- AdvertisedHost 필드에는 DNS 이름이나 IP 주소를 표기할 수 있다.

```sh
$ cd ~/githubrepo/ktds-edu-kafka

$ cat ./kafka/strimzi/kafka/13.kafka-ephemeral-auth-nodeport.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    version: 3.6.1
    replicas: 3
    authorization:
      type: simple
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
        authentication:
          type: scram-sha-512
      - name: tls
        port: 9093
        type: internal
        tls: true

      ## nodeport type 등록 -------
      - name: external
        port: 9094
        type: nodeport
        tls: false
        authentication:
          type: scram-sha-512
        configuration:
          bootstrap:
            nodePort: 32100
          brokers:
          - broker: 0
            advertisedHost: my-cluster.kafka.34.130.165.53.nip.io    # 각자의 Node IP로 변경
            nodePort: 32200
          - broker: 1
            advertisedHost: my-cluster.kafka.34.130.165.53.nip.io    # 각자의 Node IP로 변경
            nodePort: 32201
          - broker: 2
            advertisedHost: my-cluster.kafka.34.130.165.53.nip.io    # 각자의 Node IP로 변경
            nodePort: 32202
      ## nodeport type 등록 -------
....



# 각자의 Node IP로 변경
$ vi ./kafka/strimzi/kafka/13.kafka-ephemeral-auth-nodeport.yaml






# 확인
$ cat ./kafka/strimzi/kafka/13.kafka-ephemeral-auth-nodeport.yaml
...
          - broker: 0
            advertisedHost: my-cluster.kafka.34.130.165.53.nip.io    # 각자의 Node IP로 변경
            nodePort: 32200
          - broker: 1
            advertisedHost: my-cluster.kafka.34.130.165.53.nip.io    # 각자의 Node IP로 변경
            nodePort: 32201
          - broker: 2
            advertisedHost: my-cluster.kafka.34.130.165.53.nip.io    # 각자의 Node IP로 변경
...



# Cluster 적용
$ kubectl -n kafka apply -f ./kafka/strimzi/kafka/13.kafka-ephemeral-auth-nodeport.yaml

```





##### Kafka Cluster 확인

```sh

# pod 변화를 살펴보자.

$ kubectl -n kafka get pod -w
...

# 상태 확인
my-cluster-kafka-0
my-cluster-kafka-1
my-cluster-kafka-2 순서로 rolling 방식으로 재기동 될것이다.

Ctrl+C


## broker pod 3개 가 모두 재기동 될때까지 대기한다.
## 약 3분~5분 정도 소요된다.



$ kubectl -n kafka get pod
NAME                                         READY   STATUS     RESTARTS   AGE
strimzi-cluster-operator-fd6fb56f6-v265q     1/1     Running    0          52m
my-cluster-zookeeper-0                       1/1     Running    0          51m
my-cluster-zookeeper-1                       1/1     Running    0          51m
my-cluster-zookeeper-2                       1/1     Running    0          51m
my-cluster-kafka-2                           1/1     Running    0          50m
my-cluster-entity-operator-d44f86494-27plh   3/3     Running    0          49m
kafkacat-686d9c5977-pkrq7                    1/1     Running    0          46m
python-7d59455985-ml8vw                      1/1     Running    0          34m
my-cluster-kafka-0                           1/1     Running    0          50s
my-cluster-kafka-1                           0/1     Init:0/1   0          5s




# 확인
$ kubectl -n kafka get kafka my-cluster
NAME         DESIRED KAFKA REPLICAS   DESIRED ZK REPLICAS   READY   WARNINGS
my-cluster   3                        3                     True


$ kubectl -n kafka get kafka my-cluster -o yaml
...
status:
...
  - addresses:
    - host: my-cluster.kafka.34.xx.xx.xx.nip.io
      port: 32100
    bootstrapServers: my-cluster.kafka.34.xx.xx.xx.nip.io:32100
    name: external
    type: external

---

## name: external (port 32100) 이 표기되어야 정상 반영 된 것이다.


$ kubectl -n kafka get svc
NAME                                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                               AGE
my-cluster-zookeeper-client           ClusterIP   10.43.21.153    <none>        2181/TCP                              83m
my-cluster-zookeeper-nodes            ClusterIP   None            <none>        2181/TCP,2888/TCP,3888/TCP            83m
my-cluster-kafka-brokers              ClusterIP   None            <none>        9090/TCP,9091/TCP,9092/TCP,9093/TCP   82m
my-cluster-kafka-external-bootstrap   NodePort    10.43.107.247   <none>        9094:32100/TCP                        33m
my-cluster-kafka-2                    NodePort    10.43.77.231    <none>        9094:32202/TCP                        33m
my-cluster-kafka-bootstrap            ClusterIP   10.43.189.63    <none>        9091/TCP,9092/TCP,9093/TCP            82m
my-cluster-kafka-1                    NodePort    10.43.30.140    <none>        9094:32201/TCP                        33m
my-cluster-kafka-0                    NodePort    10.43.246.241   <none>        9094:32200/TCP                        33m


```



##### 접근주소 확인

외부에서 접근시 아래 주소로 cluster내부에 있는 kafka 에 접근 할 수 있다.

```sh
bootstrap  : my-cluster.kafka.34.xx.xx.xx.nip.io:32100
broker0    : my-cluster.kafka.34.xx.xx.xx.nip.io:32200
broker1    : my-cluster.kafka.34.xx.xx.xx.nip.io:32201
broker2    : my-cluster.kafka.34.xx.xx.xx.nip.io:32202


# port 가 살아 있는지 netcat 으로 확인해 보자.
$ nc -zv my-cluster.kafka.34.xx.xx.xx.nip.io 32100
Connection to my-cluster.kafka.34.xx.xx.xx.nip.io (34.xx.xx.xx) 32100 port [tcp/*] succeeded!


# 모두 succeeded 인 것을 확인할 수 있다.


# 존재하지 않는 port는 아래와 같이 refused 된다.
$ nc -zv my-cluster.kafka.34.xx.xx.xx.nip.io 32203
nc: connect to my-cluster.kafka.localhost.127.0.0.1.nip.io (127.0.0.1) port 32203 (tcp) failed: Connection refused


```





### (2) kafkacat 로 확인

Local PC(Cluster 외부) 에서  kafka 접근 가능여부를 확인하기 위해 kafkacat 을 Container 로 실행하자.

#### Container run

kafkacat 을 docker 으로 실행한다.

```sh
# 실행
$ docker run --name kafkacat -d --user root docker.io/confluentinc/cp-kafkacat:latest sleep 365d


# 확인
$ docker ps -a
CONTAINER ID   IMAGE                             COMMAND                  CREATED          STATUS                      PORTS     NAMES
3a0ae7a699ad   confluentinc/cp-kafkacat:latest   "sleep 365d"             2 weeks ago      Up 2 seconds                          kafkacat


# Container 내부로 진입( bash 명령 수행)
$ docker exec -it kafkacat bash
[root@3a0ae7a699ad appuser]#           <-- 이런 prompt 가 표기 되어야 정상

```





#### pub/sub 확인

Terminal 을 두개 실행하여 pub 과 sub을 실행해 보자.



#### sub termnial 실행

```sh

# Container 내부로 진입( bash 명령 수행)
$ docker exec -it kafkacat bash
[root@3a0ae7a699ad appuser]#           <-- 이런 prompt 가 표기 되어야 정상



export BROKERS=my-cluster.kafka.34.130.165.53.nip.io:32100
export KAFKAUSER=my-edu-admin
export PASSWORD=qKtohJldaIsr8oVkWSXhaHSDSdvnZxir        ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 
export TOPIC=my-topic
export GROUP=my-topic-group


## topic 리스트
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD -L

Metadata for all topics (from broker -1: sasl_plaintext://my-cluster.kafka.34.130.165.53.nip.io:32100/bootstrap):
 3 brokers:
  broker 0 at my-cluster.kafka.34.130.165.53.nip.io:32200
  broker 2 at my-cluster.kafka.34.130.165.53.nip.io:32202 (controller)
  broker 1 at my-cluster.kafka.34.130.165.53.nip.io:32201
 1 topics:
  topic "my-topic" with 3 partitions:
    partition 0, leader 2, replicas: 2,0,1, isrs: 0,2,1
    partition 1, leader 1, replicas: 1,2,0, isrs: 0,2,1
    partition 2, leader 0, replicas: 0,1,2, isrs: 0,2,1


# 3개의 brokers 를 확인하자.
# Internal 에서 확인했을때와 주소가 다른 것을 확인할 수 있다.
# local PC 에서 접근가능한 3개의 nodeport 주소가 kafka discovery 에 의해 반환되었다.
# kafka discovery protocol 임을 이해하자.


## consumer
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -C -o -5



## producer : 입력모드
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -P -X acks=1
  
# 임의의 text 입력


# 테스트 완료후
# Ctrl+C or Ctrl+D (exit) 수행하여 POD terminal 을 빠져나오자.
```





#### pub termnial 실행

terminal 을 한개 더 실행하여 아래와 같이 pub 테스트를 수행하자.

```sh
# Container 내부로 진입( bash 명령 수행)
$ docker exec -it kafkacat bash
[root@3a0ae7a699ad appuser]#           <-- 이런 prompt 가 표기 되어야 정상


export BROKERS=my-cluster.kafka.34.130.165.53.nip.io:32100
export KAFKAUSER=my-edu-admin
export PASSWORD=qKtohJldaIsr8oVkWSXhaHSDSdvnZxir        ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 
export TOPIC=my-topic
export GROUP=my-topic-group


## producer : 입력모드
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -P -X acks=1
  
# 임의의 text 입력


# 테스트 완료후
# Ctrl+C or Ctrl+D (exit) 수행하여 POD terminal 을 빠져나오자.
```









### (3) python 으로 확인

External access 를 위한 python 을 Container로 실행후 kafka 에 Connect 해 보자.



#### Container run

python image 를 Container 로 실행한다.

```sh
# bastion Server 에서

## docker 실행
$ docker run --name python --user root -d python:3.9 sleep 365d


# python 확인
$ docker ps -a
CONTAINER ID  IMAGE                         COMMAND     CREATED        STATUS            PORTS       NAMES
fb231e23f9f1  docker.io/library/python:3.9  sleep 365d  2 seconds ago  Up 2 seconds ago              python


# python Container 내부로 진입( bash 명령 수행)
$ docker exec -it python bash
root@a225dc4c3dd7:/#           <-- 이런 prompt 가 표기 되어야 정상

```



#### python library install

python 을 이용해서 kafka 에 접근하기 위해서는 kafka 가아닌 kafka-python 을 설치해야 한다.

```bash

# python Container 내부에서
$ pip install kafka-python
```



#### [참고] kafka host 확인

```sh
## external 접근을 위한 host (nodeport 기준)
bootstrap  : my-cluster.kafka.34.130.165.53.nip.io:32100
broker0    : my-cluster.kafka.34.130.165.53.nip.io:32200
broker1    : my-cluster.kafka.34.130.165.53.nip.io:32201
broker2    : my-cluster.kafka.34.130.165.53.nip.io:32202



# internal 접근을 위한 host 확인
# nc 명령으로 접근가능여부를 확인할 수 있다.

$ apt update
$ apt install netcat

$ nc -zv my-cluster.kafka.34.130.165.53.nip.io 32100
Connection to my-cluster.kafka.34.130.165.53.nip.io (34.130.165.53) 32100 port [tcp/*] succeeded!

```





#### consumer

consumer 실행을 위해서 python cli 환경으로 들어가자.

```sh
$ python
Python 3.9.18 (main, Aug 26 2023, 01:24:18)
[GCC 12.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.

>>>

```



CLI 환경에서 아래  Python 명령을 하나씩 실행해 보자.

```python
from kafka import KafkaConsumer

# 개인환경으로 변경
bootstrap_servers='my-cluster.kafka.34.130.165.53.nip.io:32100'
sasl_plain_password='qKtohJldaIsr8oVkWSXhaHSDSdvnZxir'             ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 
sasl_plain_username='my-edu-admin'
topic_name='my-topic' 
group_id='my-topic-group'

consumer = KafkaConsumer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username=sasl_plain_username,
                        sasl_plain_password=sasl_plain_password,
                        ssl_check_hostname=True,
                        auto_offset_reset='earliest',
                        enable_auto_commit= True,
                        group_id=group_id)

# 접속한 계정으로 확인가능한 topic 목록들을 확인할 수 있다.
consumer.topics()

# 사용할 topic 지정(구독)
consumer.subscribe(topic_name)

# 구독 확인
consumer.subscription()
#{'my-topic'}            <-- 해당 Topic 이 출력되어야 한다.


# 메세지 읽기
for message in consumer:
   print("topic=%s partition=%d offset=%d: key=%s value=%s" %
        (message.topic,
          message.partition,
          message.offset,
          message.key,
          message.value))

# 수신대기중....

'''
---
topic=my-topic partition=0 offset=38: key=None value=b'{"eventName":"a","num":88,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=39: key=None value=b'{"eventName":"a","num":90,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=40: key=None value=b'{"eventName":"a","num":96,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
'''
```







#### producer

producer 실행을 위해서 별도의 terminal 을 실행한 후 python cli 환경으로 들어가자.

```sh
# Container 내부로 진입( bash 명령 수행)
$ docker exec -it python bash
root@a225dc4c3dd7:/#


$ python
Python 3.9.18 (main, Aug 26 2023, 01:24:18)
[GCC 12.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.

>>>

```





CLI 환경에서 아래  Python 명령을 하나씩 실행해 보자.

```python
from kafka import KafkaProducer
from time import sleep

# 개인환경으로 변경
bootstrap_servers='my-cluster.kafka.34.130.165.53.nip.io:32100'
sasl_plain_password='qKtohJldaIsr8oVkWSXhaHSDSdvnZxir'             ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 
sasl_plain_username='my-edu-admin'
topic_name='my-topic' 
group_id='my-topic-group'

producer = KafkaProducer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        ssl_check_hostname=True,
                        sasl_plain_username=sasl_plain_username,
                        sasl_plain_password=sasl_plain_password)

# 아래 명령 부터 Consumer 수신을 관찰하면서 수행하자.
producer.send(topic_name, b'python test1')
producer.send(topic_name, b'python test2')
producer.send(topic_name, b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % 1)

# 10000건을 1초에 한번씩 발송해보자.
for i in range(10000):
    print(i)
    sleep(1)
    producer.send(topic_name, b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)

# 테스트를 끝내려면 Ctrl + C 로 중지하자.

```



- 대량 발송(성능테스트)

```python
# 만건 테스트
import time
start_time = time.time() # 시작시간
for i in range(10000):
    print(i)
    producer.send(topic_name, b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)

end_time = time.time() # 종료시간
print("duration time :", end_time - start_time)  # 현재시각 - 시작시간 = 실행 시간



# 1만건 테스트
# duration time : 9.254887104034424
# duration time : 10.304309129714966

```

- 결론
  - 일반적으로 External 이 Internal 보다 network 부하가 심해서 속도가 훨씬 느리다.
  - 하지만 우리가 테스트한 환경은 동일 PC 에서 실행하므로 속도가 거의 동일한 점을 참고하자.



- 참고

```python
# 2만건 테스트
for i in range(10001, 20000):
    print(i)
    producer.send(topic_name, b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)
    
```



- python 종료 Ctrl+D 

```sh
# POD Terminal 을 빠져나가려면 exit(Ctrl+D)
```





### (4) kafkacat / python 으로 확인

sub 은 python 으로 유지하면서 pub 은 kafkacat 으로 데이터를 전송하는 테스트를 진행해 보자.







## 4) [참고] Route

Openshift 를 사용하는 경우 Route로 접근할 수 있다.



#### Route Listener 등록

- Kafka Cluster 를 수정모드로 변경하여 Route  listener 를 삽입하자.
- node Port 를 직접 명시할 수 있다.
- AdvertisedHost 필드에는 DNS 이름이나 IP 주소를 표기할 수 있다.



```yaml

apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster
  namespace: kafka
spec:
  kafka:
    version: 3.5.1
    replicas: 3
    authorization:
      type: simple
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
        authentication:
          type: scram-sha-512
      - name: tls
        port: 9093
        type: internal
        tls: true

      - name: external
        port: 9094
        type: route
        tls: true
        authentication:
          type: tls
        configuration:
          bootstrap:
            host: bootstrap.kafka.apps.211-34-231-82.nip.io
          brokers:
          - broker: 0
            host: broker-0.kafka.apps.211-34-231-82.nip.io
          - broker: 1
            host: broker-1.kafka.apps.211-34-231-82.nip.io
          - broker: 2
            host: broker-2.kafka.apps.211-34-231-82.nip.io
            
            
      - authentication:
          sasl: true
          type: tls
        configuration:
          bootstrap:
            host: bootstrap.kafka.apps.211-34-231-82.nip.io
          brokers:
            - broker: 0
              advertisedHost: broker-0.kafka.apps.211-34-231-82.nip.io
              advertisedPort: 443
            - broker: 1
              advertisedHost: broker-1.kafka.apps.211-34-231-82.nip.io
              advertisedPort: 443
            - broker: 2
              advertisedHost: broker-2.kafka.apps.211-34-231-82.nip.io
              advertisedPort: 443
            
....
```





## 5) [참고] Python Admin 

### (1) Consumer Group List 

```python
from kafka.admin import KafkaAdminClient

# 개인환경으로 변경
bootstrap_servers='my-cluster.kafka.localhost.192.168.31.1.nip.io:32100'
sasl_plain_password='PkcAIUblNHFg'             ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 

admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers, 
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username='my-user',
                        sasl_plain_password=sasl_plain_password,
                        #client_id='test1'
                        )

list_cg = admin_client.list_consumer_groups()
print(type(list_cg))
print(list_cg )
# [('my-topic-group', 'consumer')]

```



### (2) describe_consumer_groups

CG 명을 던져서 topicname, partition, current-offset 이 리턴되어야 한다.

참조: https://kafka-python.readthedocs.io/en/master/apidoc/KafkaAdminClient.html

참조: https://github.com/dpkp/kafka-python/issues/1798

```python
from kafka.admin import KafkaAdminClient

# 개인환경으로 변경
bootstrap_servers='my-cluster.kafka.localhost.192.168.31.1.nip.io:32100'
sasl_plain_password='PkcAIUblNHFg'             ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 

admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers, 
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username='my-user',
                        sasl_plain_password=sasl_plain_password,
                        #client_id='test1'
                        )

# 그룹명을 인수로 보낼때는 반드시 리스트[] 로 보내야 한다.
cg_desc = admin_client.describe_consumer_groups(['my-topic-group'])
print(type(cg_desc))
print(cg_desc)

'''
[
GroupInformation(
error_code=0, 
group='my-topic-group', 
state='Stable', 
protocol_type='consumer', 
protocol='range', 
members=[MemberInformation(member_id='kafka-python-2.0.2-06e95b4b-6f67-467d-ac8e-64c34710c5a2', 
client_id='kafka-python-2.0.2', 
client_host='/192.168.65.3', 
member_metadata=ConsumerProtocolMemberMetadata(version=0, subscription=['my-topic'], user_data=b''), 
member_assignment=ConsumerProtocolMemberAssignment(version=0, 
assignment=[(topic='my-topic', partitions=[0, 1, 2])], 
user_data=b''))], 
authorized_operations=None)
]
'''



# offset 정보
cg_offsets = admin_client.list_consumer_group_offsets('my-topic-group')
print(type(cg_offsets))
print(cg_offsets)

'''
{
TopicPartition(topic='my-topic', partition=0): OffsetAndMetadata(offset=13449, metadata=''), 
TopicPartition(topic='my-topic', partition=1): OffsetAndMetadata(offset=13534, metadata=''), 
TopicPartition(topic='my-topic', partition=2): OffsetAndMetadata(offset=13151, metadata='')
}
'''

```



### (3) kafka admin Client

- topic 생성시

```python
from kafka.admin import KafkaAdminClient, NewTopic

# 개인환경으로 변경
bootstrap_servers='my-cluster.kafka.localhost.192.168.31.1.nip.io:32100'
sasl_plain_password='eGVNg7ZvPbi0'

admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers, 
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username='my-user',
                        sasl_plain_password=sasl_plain_password,
                        #client_id='test1'
                        )

topic_list = []
topic_list.append(NewTopic(name="example_topic", num_partitions=1, replication_factor=1))
admin_client.create_topics(new_topics=topic_list, validate_only=False)

'''
---
python kafkaAdminClient.py
---
'''
```







# 5. Strimzi Clean up

Bastion Server 에서의 Strimzi 실습이 완료되었다. 불필요한 리소스 사용을 없애기 위해서 깨끗히 삭제하도록 하자.

필요시 추후 삭제하도록 하자.



## 1) Strimzi All Clean Up

```sh
# bastion Server 에서...

# 1) client tool clean up
$ kubectl -n kafka delete deploy kafkacat
  kubectl -n kafka delete deploy python


# 2) 확인
$ kubectl -n kafka get kafkauser
  kubectl -n kafka get kafkatopic
  kubectl -n kafka get all


# 3) kafka resource clean up
$ kubectl -n kafka delete kafkauser my-edu-admin
  kubectl -n kafka delete kafkatopic my-topic
  kubectl -n kafka delete kafka my-cluster


# 4) strimzi clean up
$ cd ~/githubrepo/ktds-edu-kafka
$ kubectl -n kafka delete -f ./kafka/strimzi/install/cluster-operator

# 5) kafka namespace clean up
$ kubectl delete namespace kafka

# 6) 확인
$ kubectl -n kafka get kafkauser
$ kubectl -n kafka get kafkatopic
$ kubectl -n kafka get all

# 7) strimzi directory
$ cd
$ rm -rf ~/temp/strimzi

```





## 2) Container Clean up

```sh
# bastion Server 에서

# 확인
$ docker ps -a
CONTAINER ID  IMAGE                                      COMMAND     CREATED         STATUS             PORTS       NAMES
598840f3a513  docker.io/library/python:3.9               sleep 365d  49 minutes ago  Up 49 minutes ago              python
add15a7fd413  docker.io/confluentinc/cp-kafkacat:latest  sleep 365d  22 minutes ago  Up 22 minutes ago              kafkacat


# 1) Container 삭제
$ docker rm -f python
  docker rm -f kafkacat

$ docker ps -a


```





# 6. [EduCluster] Kafka Cluster 접근

그 동안 한개의 Node 로 구성된 Bastion Server 를 이용하여 테스트를 수행하였지만 다수의 사용자들이 접속하여 테스트가 가능한 안정적인 서버가 필요하다.  또한 모니터링등 좀 더 많은 리소스를 사용하는 Tool 의 안정적인 서비스를 위해서 별도의 공용서버가 준비되어 있다.

아래 실습 부터는 공용서버에서 수행한다.



## 1) Monitoring

이미 설치되어 있는 Monitoring tool 을 함께 보면서 실습을 할 것이다.

### (1) kafdrop

* 링크 : http://kafdrop.kafka.43.203.62.69.nip.io/

![image-20230611132914031](assets/image-20230611132914031.png)



### (2) grafana

* 링크 : http://grafana.kafka.43.203.62.69.nip.io/d/jwPKIsniz/strimzi-kafka-exporter?orgId=1&refresh=5s
* ID / Pass : admin / adminpass

- 메뉴 위치 : Dashboards > Manage > Strimzi Kafka Exporter

![image-20220626111254872](assets/image-20220626111254872.png)





## 2) 수강생별 topic 접속정보

별도공지





## 3) 공용서버 Kafka Access(Node Port)



### (1) 접속정보 확인



#### 접속 Domain(IP) 확인

공용서버 접근을 위한 외부IP와 Node Port를 확인하자.

```sh
bootstrap  : my-cluster.kafka.43.203.62.69.nip.io:32100
broker0    : my-cluster.kafka.43.203.62.69.nip.io:32200
broker1    : my-cluster.kafka.43.203.62.69.nip.io:32201
broker2    : my-cluster.kafka.43.203.62.69.nip.io:32202


# port 가 살아 있는지 netcat 으로 확인해 보자.
$ nc -zv my-cluster.kafka.43.203.62.69.nip.io 32100
Connection to my-cluster.kafka.43.203.62.69.nip.io (43.203.62.69) 32100 port [tcp/*] succeeded!


# 모두 succeeded 인 것을 확인할 수 있다.

```





#### 접속 계정 확인 - ★★★

```sh

# user/pass 
## edu-user / oXTjENLJMvdKV6CbQmU2NX0e87Rezxhc

```







### (2) [참고] kafkacat 로 확인

Local PC(Cluster 외부) 에서  kafka 접근 가능여부를 확인하기 위해 kafkacat 을 Container 로 실행하자.

#### Container run

kafkacat 을 docker 으로 실행한다.

```sh
# 실행
$ docker run --name kafkacat -d --user root docker.io/confluentinc/cp-kafkacat:latest sleep 365d


# 확인
$ docker ps -a
CONTAINER ID   IMAGE                             COMMAND                  CREATED          STATUS                      PORTS     NAMES
3a0ae7a699ad   confluentinc/cp-kafkacat:latest   "sleep 365d"             2 weeks ago      Up 2 seconds                          kafkacat


# Container 내부로 진입( bash 명령 수행)
$ docker exec -it kafkacat bash
[root@3a0ae7a699ad appuser]#           <-- 이런 prompt 가 표기 되어야 정상

```



#### pub/sub 확인

password  와 주소를 확인한 후 변경하자.

```sh


# Container 내부로 진입( bash 명령 수행)
$ docker exec -it kafkacat bash

[root@eed489be3084 appuser]#


export BROKERS=my-cluster.kafka.43.203.62.69.nip.io:32100
export KAFKAUSER=edu-user
export PASSWORD=oXTjENLJMvdKV6CbQmU2NX0e87Rezxhc
export TOPIC=edu-topic01         # <-- 본인 topic명으로 지정
export GROUP=edu-topic01-cg      # <-- 본인 group명으로 지정


## topic 리스트
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD -L


Metadata for all topics (from broker -1: sasl_plaintext://my-cluster.kafka.43.203.62.69.nip.io:32100/bootstrap):
 3 brokers:
  broker 0 at my-cluster.kafka.43.203.62.69.nip.io:32200
  broker 2 at my-cluster.kafka.43.203.62.69.nip.io:32202 (controller)
  broker 1 at my-cluster.kafka.43.203.62.69.nip.io:32201

 21 topics:
  topic "edu-topic05" with 3 partitions:
    partition 0, leader 1, replicas: 1,2, isrs: 1,2
    partition 1, leader 0, replicas: 0,1, isrs: 0,1
    partition 2, leader 2, replicas: 2,0, isrs: 2,0
  topic "edu-topic16" with 3 partitions:
    partition 0, leader 2, replicas: 2,1, isrs: 2,1
    partition 1, leader 1, replicas: 1,0, isrs: 1,0
    partition 2, leader 0, replicas: 0,2, isrs: 0,2
  topic "edu-topic01" with 3 partitions:
    partition 0, leader 2, replicas: 2,1, isrs: 2,1
    partition 1, leader 1, replicas: 1,0, isrs: 1,0
    partition 2, leader 0, replicas: 0,2, isrs: 0,2




## consumer
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -C -o -5



## terminal 을 한개 더 실행하여 위 환경변수 인식후 아래 producer 를 실행하자.
## producer : 입력모드
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -P -X acks=1
  
# 임의의 text 입력


# 테스트 완료후
# Ctrl+C or Ctrl+D (exit) 수행하여 POD terminal 을 빠져나오자.
```





### (3) python 으로 확인

External access 를 위한 python 을 Container로 실행후 kafka 에 Connect 해 보자.



#### Bastion Server Container run ★

python image 를 Container 로 실행한다.

```sh
# bastion Server 에서

## docker 실행
$ docker run --name python --user root -d python:3.9 sleep 365d


# python 확인
$ docker ps -a
CONTAINER ID  IMAGE                         COMMAND     CREATED        STATUS            PORTS       NAMES
fb231e23f9f1  docker.io/library/python:3.9  sleep 365d  2 seconds ago  Up 2 seconds ago              python


# python Container 내부로 진입( bash 명령 수행)
$ docker exec -it python bash
root@a225dc4c3dd7:/#           <-- 이런 prompt 가 표기 되어야 정상

```



#### python library install

python 을 이용해서 kafka 에 접근하기 위해서는 kafka 가아닌 kafka-python 을 설치해야 한다.

```bash
# python Container 내부에서
$ pip install kafka-python
```



#### consumer

consumer 실행을 위해서 python cli 환경으로 들어가자.

```sh
$ python
Python 3.9.18 (main, Aug 26 2023, 01:24:18)
[GCC 12.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.

>>>

```



CLI 환경에서 아래  Python 명령을 하나씩 실행해 보자.

```python

from kafka import KafkaConsumer

# 개인환경으로 변경
bootstrap_servers='my-cluster.kafka.43.203.62.69.nip.io:32100'
sasl_plain_username='edu-user'
sasl_plain_password='oXTjENLJMvdKV6CbQmU2NX0e87Rezxhc'
topic_name='edu-topic01'         # <-- 본인 topic명으로 지정
group_id='edu-topic01-cg'        # <-- 본인 group명으로 지정


consumer = KafkaConsumer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username=sasl_plain_username,
                        sasl_plain_password=sasl_plain_password,
                        ssl_check_hostname=True,
                        auto_offset_reset='earliest',
                        enable_auto_commit= True,
                        group_id=group_id)

# 접속한 계정으로 확인가능한 topic 목록들을 확인할 수 있다.
consumer.topics()

# 사용할 topic 지정(구독)
consumer.subscribe(topic_name)

# 구독 확인
consumer.subscription()
#{'edu-topic01'}            <-- 본인의 Topic이 출력되어야 한다.


# 메세지 읽기
for message in consumer:
   print("topic=%s partition=%d offset=%d: key=%s value=%s" %
        (message.topic,
          message.partition,
          message.offset,
          message.key,
          message.value))

# 수신대기중....

'''
---
topic=my-topic partition=0 offset=38: key=None value=b'{"eventName":"a","num":88,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=39: key=None value=b'{"eventName":"a","num":90,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=40: key=None value=b'{"eventName":"a","num":96,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
'''
```







#### producer

producer 실행을 위해서 별도의 terminal 을 실행한 후 python cli 환경으로 들어가자.

```sh
# Container 내부로 진입( bash 명령 수행)
$ docker exec -it python bash
root@a225dc4c3dd7:/#


$ python
Python 3.9.18 (main, Aug 26 2023, 01:24:18)
[GCC 12.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.

>>>

```





CLI 환경에서 아래  Python 명령을 하나씩 실행해 보자.

```python

from kafka import KafkaProducer
from time import sleep

# 개인환경으로 변경
bootstrap_servers='my-cluster.kafka.43.203.62.69.nip.io:32100'
sasl_plain_username='edu-user'
sasl_plain_password='oXTjENLJMvdKV6CbQmU2NX0e87Rezxhc'
topic_name='edu-topic01'      # <-- 본인 타픽명으로 지정


producer = KafkaProducer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        ssl_check_hostname=True,
                        sasl_plain_username=sasl_plain_username,
                        sasl_plain_password=sasl_plain_password)

# 아래 명령 부터 Consumer 수신을 관찰하면서 수행하자.
producer.send(topic_name, b'python test1')
producer.send(topic_name, b'python test2')
producer.send(topic_name, b'python test2', b'k1')
producer.send(topic_name, b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % 1)

# 10000건을 1초에 한번씩 발송해보자.
for i in range(10000):
    print(i)
    sleep(1)
    producer.send(topic_name, b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)

# 테스트를 끝내려면 Ctrl + C 로 중지하자.

```



* 모니터링 결과 확인
  * Kafdrop 확인
    * 링크 : http://kafdrop.kafka.43.203.62.69.nip.io
  * Grafana 확인
    * 링크 : http://grafana.kafka.43.203.62.69.nip.io
    * 메뉴 위치 : Dashboards > Manage > Strimzi Kafka Exporter
  * Consumer 중단시 Lag 값 증가 현상 확인



- python 종료 Ctrl+D 

```sh
# POD Terminal 을 빠져나가려면 exit(Ctrl+D)
```













# 7.  Java - STS

Java 실습은 Spring Boot (STS) 를 이용해서 진행할 것이다.  

EduCluster에 Kafka 와 관련 모니터링 툴(Prometheus, Grafana)이 설치 되어 있으며  이 환경에 접속하여 실습을 진행할 것이다.



 

## 1) 사전정보 확인



### (1) 개인 Topic 정보

 실습을 위해서 Topic/Group/User 정보 대해서 아래와 같이 준비되어 있다.



#### 개인별 할당 Topic 확인

```sh
# topic
edu-topic01 ~ edu-topic20
 
# group - 사용자가 consum 할때 선언함
edu-topic01-cg ~ edu-topic20-cg
 
```

* 관련 링크 :  ( [가이드 문서 보기](../beforebegin/beforebegin.md) )
  * 시시작전 문서 중    `3.1 수강생별 접속 서버 주소`   확인





### (2) 공용 접속 정보 확인

EduCluster 의 kafka Cluster를 접속한다.

```sh
# kafka bootstrap-servers
my-cluster.kafka.43.203.62.69.nip.io:32100

# user/pass 
edu-user / nxRcaiHkAOi9YhaFcm3zn6STlWyqivCf

```



## 2) kafka-consumer

java 에서 kafka consumer 를 실행하는 방법은 다양하게 존재하지만 본 실습에서는 @KafkaListener 방식을 활용한다.

PC 에 설치되어 있는 STS 를 실행하자.



### (1) sample import

- STS 에서 import 
  - Package Explorer 에서 우클릭 이후 아래 메뉴 선택


```
1) import > Maven > Existing Maven Projects

2) Root Directory
   directory 선택 : C:\githubrepo\ktds-edu-kafka\kafka\SpringBootSample\kafka-sample-consumer

3) finish
```





### (2) 소스내 Topic/Group 수정

- application.yml 파일 수정
  - 위치
    - src/main/resources/application.yml

  - 수정내용


```yaml
server:
  port: 8080
     
spring:
  application:
    name: kafka-consumer
    
  kafka:
    bootstrap-servers: my-cluster.kafka.43.203.62.69.nip.io:32100
    security:
      protocol: SASL_PLAINTEXT
    properties:
      sasl:
        jaas:
          config: org.apache.kafka.common.security.scram.ScramLoginModule required username="edu-user" password="oXTjENLJMvdKV6CbQmU2NX0e87Rezxhc";
        mechanism: SCRAM-SHA-512
     
    consumer:
      group-id: edu-topic__-cg         # 본인의 그룹명으로 수정할것

topic:
  name: edu-topic__                 # 본인의 토픽명으로 수정할것
```

 

### (3) Consumer 실행

```
[Package Explorer] 
- kafka-consumer 에서 우측버튼 클릭
- Run As 
- Spring Boot App 실행
```



- Console log 확인

```
...
edu-topic01-cg: partitions assigned: [edu-topic01-0, edu-topic01-1, edu-topic01-2]
```

- 3개의 partition 이 모두 하나의 Consumer 에 assigned 되었다.
- 차후 리발린싱 테스트시 어떻게 변경되는지 확인해 볼 것이다.





## 3) kafka-producer

java 에서 kafka producer를 실행하는 방법은 다양하게 존재하지만 본 실습에서는 KafkaTemplate 방식을 활용한다.



###  (0) [참고] KafkaTemplate

* 일반적으로 kafka 에 Message 를 Send하려면 KafkaProducer인스턴스를 사용하여 Send() 메서드를 호출해야 한다.  
* KafkaTemplate 은 좀서 쉽게 사용할 수 있도록 만들어진 KafkaProducer를 감싸고 있는 인스턴스이다.

 

### (1) sample import

- STS 에서 import
  - Package Explorer 에서 우클릭 이후 아래 메뉴 선택

```
1) import > Maven > Existing Maven Projects

2) Root Directory
   directory 선택 : C:\githubrepo\ktds-edu-kafka\kafka\SpringBootSample\kafka-sample-producer

3) finish
```



### (2) 소스내 Topic 수정

src/main/resources/config/application-local.yaml 에서 아래 내용 수정

```yaml
server:
  port: 8081


spring:
  application:
    name: kafka-producer
    
  kafka:
    bootstrap-servers: my-cluster.kafka.43.203.62.69.nip.io:32100
    security:
      protocol: SASL_PLAINTEXT
    properties:
      sasl:
        jaas:
          config: org.apache.kafka.common.security.scram.ScramLoginModule required username="my-user" password="oXTjENLJMvdKV6CbQmU2NX0e87Rezxhc";
        mechanism: SCRAM-SHA-512

topic:
  name: edu-topic__                 # 본인의 토픽명으로 수정할것

```

 

### (3) producer 실행

```
[Package Explorer] 
- kafka-producer 에서 우측버튼 클릭
- Run As 
- Spring Boot App 실행
```

 

- Console log 확인

```
...
Tomcat started on port(s): 8081 (http) with context path ''
```



### (4) pub test (create api call)

postman 이나 curl 을 통해서 아래와 같이 테스트를 수행한다.

Local Terminal(window command, gitbash, mobaxterm shell) 에서 수행해야 함을 유의하자.

```sh
$ curl -X GET http://localhost:8081/publish?message=test


## 초당 1회 call 발생(producer )
$ while true; do curl -X GET http://localhost:8081/publish?message=test; date; echo;sleep 1; echo; done

```





### (5) Monitoring 확인

- 모니터링 결과 확인
  * Kafdrop 확인
    * 링크 : http://kafdrop.kafka.43.203.62.69.nip.io
  * Grafana 확인
    * 링크 : http://grafana.kafka.43.203.62.69.nip.io
    * 메뉴 위치 : Dashboards > Manage > Strimzi Kafka Exporter



